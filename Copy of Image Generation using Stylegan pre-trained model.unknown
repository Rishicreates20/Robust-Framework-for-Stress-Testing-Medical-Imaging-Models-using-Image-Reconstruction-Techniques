{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"colab":{"provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/image-generation-using-stylegan-pre-trained-model-f7ac165e-bfc3-42b5-9660-70408e435e65.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20241227/auto/storage/goog4_request&X-Goog-Date=20241227T035017Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=293ac501ce7c4861ef0a1803b716e509464e09fef6cb6534b4744bbbb75083ccfcf441ccf04231b7032db923462cd1cc455fa9769190b6420ce01222eff92a21194dbc7832e52d0195cde5aac02712cb4be6ede2c756f873539aae19ec71377ff6b1a0499226439a4265678f502fe0edd01759c736be4502984b57ad8ca5f05f225609c30a476173f102fffb0242c144d855f7ac8110278b687c996278c9b0edd8723783d3e55d69c2ee56408fea43550874ab7a3badbfc94fdde7d21b295c9bc78c4d614fd21b1052eb346bfac2c892c16f27d1d9ecac0004e72fa7620773ec56f42eec60abd06ecadf0fe2242927851b704ec90f40f7dc9dc0a9a80811e914","timestamp":1735271479419}]}},"nbformat_minor":0,"nbformat":4,"cells":[{"source":["# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","import kagglehub\n","greatgamedota_ffhq_face_data_set_path = kagglehub.dataset_download('greatgamedota/ffhq-face-data-set')\n","songseungwon_ffhq_1024x1024_pretrained_path = kagglehub.dataset_download('songseungwon/ffhq-1024x1024-pretrained')\n","\n","print('Data source import complete.')\n"],"metadata":{"id":"dE2xT8cXPJIH"},"cell_type":"code","outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# Image Generation using Stylegan pre-trained model"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","id":"Kj4-es7cPJIK"}},{"cell_type":"markdown","source":["In this kernel, I will focus on trying out a pre-trained stylegan model.\n","\n","Therefore, understanding of the background knowledge of gan should be preceded, and it is good to check in advance how stylegan is implemented through the official TensorFlow code. (We'll use PyTorch more simply.) So let's get started.\n","\n","- [PyTorchðŸ”¥ GAN Basic Tutorial for beginner](https://www.kaggle.com/songseungwon/pytorch-gan-basic-tutorial-for-beginner)\n","\n","\n","And, this kernel uses [lernapparat's Jupyter notebook (which recreates the StyleGAN for use with the pretrained weights)](https://github.com/sw-song/lernapparat/blob/master/style_gan/pytorch_style_gan.ipynb) as the base code. I added some test code and refined the structure. Thanks to lernapparat for the nice code sharing."],"metadata":{"id":"JFZ183Z8PJIM"}},{"cell_type":"markdown","source":["[-->paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)\n","\n","![-->paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.pdf)"],"metadata":{"id":"UPlyFKHVPJIO"}},{"cell_type":"markdown","source":["## Main Reference\n","1. [PyTorch-GAN | Github/lernapparat | PyTorch implementation of the StyleGAN Generator](https://github.com/sw-song/lernapparat/blob/master/style_gan/pytorch_style_gan.ipynb)\n","2. [stylegan | Github/NVlabs | Official](https://github.com/NVlabs/stylegan)\n","3. [StyleGAN: Use machine learning to generate and customize realistic images](https://heartbeat.fritz.ai/stylegans-use-machine-learning-to-generate-and-customize-realistic-images-c943388dc672)"],"metadata":{"id":"P49nV_JjPJIP"}},{"cell_type":"markdown","source":["## Preview"],"metadata":{"id":"pk6X2p7dPJIP"}},{"cell_type":"markdown","source":["![image](https://miro.medium.com/max/1400/1*mDA1ms7D5NrwKXp4r2CXQQ.png)"],"metadata":{"id":"WZkiDYU8PJIQ"}},{"cell_type":"markdown","source":["> Copying the styles corresponding to coarse spatial resolutions brings high-level aspects such as pose, general hair style, face shape, and eyeglasses from source B, while all colors (eyes, hair, lighting) and finer facial features resemble source A."],"metadata":{"id":"v0-2tNnYPJIR"}},{"cell_type":"markdown","source":["## Structure"],"metadata":{"id":"Dv5s85mBPJIS"}},{"cell_type":"markdown","source":["![image](https://bloglunit.files.wordpress.com/2019/02/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2019-02-24-e1848be185a9e18492e185ae-3.43.31.png)"],"metadata":{"id":"_71ToBeZPJIT"}},{"cell_type":"markdown","source":["> The generator in a traditional GAN vs the one used by NVIDIA in the StyleGAN"],"metadata":{"id":"NLh3BODlPJIT"}},{"cell_type":"markdown","source":["## Index\n","```\n","Step 1. Import Libraries\n","Step 2. Design Layers\n","     2-a. linear layer\n","     2-b. convolution layer\n","     2-c. noise layer\n","     2-d. style modification layer\n","     2-e. pixel normalization layer\n","     2-f. blur layer\n","     2-g. upscaling layer\n","Step 3. Design Networks\n","     3-a. generator mapping network\n","     3-b. generator synthesis blocks\n","     3-c. generator synthesis network\n","Step 4. Define the Model (Image Generator)\n","     4-a. data flow : z to image\n","     4-b. load pre-trained weight\n","Step 5. Test the Model\n","     5-a. gpu setting\n","     5-b. input setting - grid\n","     5-c. input setting - latent z\n","     5-d. show samples\n","Step 6. Control Latent Vector\n","     6-a. first random latent vector + generate first image\n","     6-b. second random latent vector + generate second image\n","     6-c. half `z` + half `z`\n","     6-d. half `w` + half `w`\n","     6-e. Image Interpolation Comparison\n","```\n","---"],"metadata":{"id":"Q9KFgr6rPJIU"}},{"cell_type":"markdown","source":["### Step 1. Import Libraries"],"metadata":{"id":"QoYj3g1DPJIV"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from collections import OrderedDict\n","import pickle\n","\n","import numpy as np\n","\n","import IPython"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.277918Z","iopub.execute_input":"2021-06-24T11:13:07.278845Z","iopub.status.idle":"2021-06-24T11:13:07.622328Z","shell.execute_reply.started":"2021-06-24T11:13:07.278709Z","shell.execute_reply":"2021-06-24T11:13:07.621396Z"},"trusted":true,"id":"hxSVmC_BPJIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 2. Design Layers"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T02:02:59.87609Z","iopub.execute_input":"2021-06-24T02:02:59.876943Z","iopub.status.idle":"2021-06-24T02:02:59.882755Z","shell.execute_reply.started":"2021-06-24T02:02:59.876892Z","shell.execute_reply":"2021-06-24T02:02:59.881507Z"},"id":"VWCIdUwUPJIW"}},{"cell_type":"markdown","source":["**2-a. Linear Layer**"],"metadata":{"id":"rIfh2jogPJIW"}},{"cell_type":"code","source":["class MyLinear(nn.Module):\n","    \"\"\"Linear layer with equalized learning rate and custom learning rate multiplier.\"\"\"\n","    def __init__(self, input_size, output_size, gain=2**(0.5), use_wscale=False, lrmul=1, bias=True):\n","        super().__init__()\n","        he_std = gain * input_size**(-0.5) # He init\n","        # Equalized learning rate and custom learning rate multiplier.\n","        if use_wscale:\n","            init_std = 1.0 / lrmul\n","            self.w_mul = he_std * lrmul\n","        else:\n","            init_std = he_std / lrmul\n","            self.w_mul = lrmul\n","        self.weight = torch.nn.Parameter(torch.randn(output_size, input_size) * init_std)\n","        if bias:\n","            self.bias = torch.nn.Parameter(torch.zeros(output_size))\n","            self.b_mul = lrmul\n","        else:\n","            self.bias = None\n","\n","    def forward(self, x):\n","        bias = self.bias\n","        if bias is not None:\n","            bias = bias * self.b_mul\n","        return F.linear(x, self.weight * self.w_mul, bias)\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.624685Z","iopub.execute_input":"2021-06-24T11:13:07.624953Z","iopub.status.idle":"2021-06-24T11:13:07.634852Z","shell.execute_reply.started":"2021-06-24T11:13:07.62492Z","shell.execute_reply":"2021-06-24T11:13:07.63402Z"},"trusted":true,"id":"3Hi32O7nPJIW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> With this Class, Targeted initialization is performed for each layer.\n","It allows generator to follow the targeted style distribution."],"metadata":{"id":"cYMgbHmzPJIX"}},{"cell_type":"markdown","source":["![image](https://bloglunit.files.wordpress.com/2019/02/e18489e185b3e1848fe185b3e18485e185b5e186abe18489e185a3e186ba-2019-02-24-e1848be185a9e18492e185ae-5.42.19.png?w=1222)"],"metadata":{"id":"a13ZGWirPJIX"}},{"cell_type":"markdown","source":["> TEST CODE :"],"metadata":{"id":"7E1hAIVDPJIY"}},{"cell_type":"code","source":["gain = 2**(0.5)\n","gain"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.6366Z","iopub.execute_input":"2021-06-24T11:13:07.63712Z","iopub.status.idle":"2021-06-24T11:13:07.65422Z","shell.execute_reply.started":"2021-06-24T11:13:07.637069Z","shell.execute_reply":"2021-06-24T11:13:07.653387Z"},"trusted":true,"id":"BhwGRtuwPJIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["he_std = gain*(512**(-0.5)) # input_size = 512\n","he_std"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.657637Z","iopub.execute_input":"2021-06-24T11:13:07.657938Z","iopub.status.idle":"2021-06-24T11:13:07.665157Z","shell.execute_reply.started":"2021-06-24T11:13:07.657907Z","shell.execute_reply":"2021-06-24T11:13:07.664115Z"},"trusted":true,"id":"at4Iwc8xPJIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lrmul = 1\n","init_std = 1.0/lrmul\n","print(init_std)\n","print('w_mul when use wscale :',he_std*init_std)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.666445Z","iopub.execute_input":"2021-06-24T11:13:07.667418Z","iopub.status.idle":"2021-06-24T11:13:07.676245Z","shell.execute_reply.started":"2021-06-24T11:13:07.667387Z","shell.execute_reply":"2021-06-24T11:13:07.675171Z"},"trusted":true,"id":"_WGfLptmPJIY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.randn(512,512)*init_std"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.677507Z","iopub.execute_input":"2021-06-24T11:13:07.678013Z","iopub.status.idle":"2021-06-24T11:13:07.694125Z","shell.execute_reply.started":"2021-06-24T11:13:07.677972Z","shell.execute_reply":"2021-06-24T11:13:07.693155Z"},"trusted":true,"id":"ku8Fw6V4PJIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["weight = torch.nn.Parameter(torch.randn(512,512)*init_std) # Parameter(..) ==> requires_grad=True\n","weight"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.695365Z","iopub.execute_input":"2021-06-24T11:13:07.695759Z","iopub.status.idle":"2021-06-24T11:13:07.708493Z","shell.execute_reply.started":"2021-06-24T11:13:07.695721Z","shell.execute_reply":"2021-06-24T11:13:07.707555Z"},"trusted":true,"id":"LmCQqjNUPJIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bias = torch.nn.Parameter(torch.zeros(512,512))\n","bias"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.711495Z","iopub.execute_input":"2021-06-24T11:13:07.711807Z","iopub.status.idle":"2021-06-24T11:13:07.720817Z","shell.execute_reply.started":"2021-06-24T11:13:07.71178Z","shell.execute_reply":"2021-06-24T11:13:07.719828Z"},"trusted":true,"id":"g4qZRsjwPJIZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w_mul = lrmul\n","b_mul = lrmul\n","\n","F.linear(torch.randn(512,512), weight*w_mul, bias*b_mul)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.722344Z","iopub.execute_input":"2021-06-24T11:13:07.722591Z","iopub.status.idle":"2021-06-24T11:13:07.743972Z","shell.execute_reply.started":"2021-06-24T11:13:07.722567Z","shell.execute_reply":"2021-06-24T11:13:07.742996Z"},"trusted":true,"id":"uurZzR21PJIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-b. Convolution Layer**"],"metadata":{"id":"K1Asnxl8PJIa"}},{"cell_type":"code","source":["class MyConv2d(nn.Module):\n","    \"\"\"Conv layer with equalized learning rate and custom learning rate multiplier.\"\"\"\n","    def __init__(self, input_channels, output_channels, kernel_size, gain=2**(0.5), use_wscale=False, lrmul=1, bias=True,\n","                intermediate=None, upscale=False):\n","        super().__init__()\n","        if upscale:\n","            self.upscale = Upscale2d()\n","        else:\n","            self.upscale = None\n","        he_std = gain * (input_channels * kernel_size ** 2) ** (-0.5) # He init\n","        self.kernel_size = kernel_size\n","        if use_wscale:\n","            init_std = 1.0 / lrmul\n","            self.w_mul = he_std * lrmul\n","        else:\n","            init_std = he_std / lrmul\n","            self.w_mul = lrmul\n","        self.weight = torch.nn.Parameter(torch.randn(output_channels, input_channels, kernel_size, kernel_size) * init_std)\n","        if bias:\n","            self.bias = torch.nn.Parameter(torch.zeros(output_channels))\n","            self.b_mul = lrmul\n","        else:\n","            self.bias = None\n","        self.intermediate = intermediate\n","\n","    def forward(self, x):\n","        bias = self.bias\n","        if bias is not None:\n","            bias = bias * self.b_mul\n","\n","        have_convolution = False\n","        if self.upscale is not None and min(x.shape[2:]) * 2 >= 128:\n","            # this is the fused upscale + conv from StyleGAN, sadly this seems incompatible with the non-fused way\n","            # this really needs to be cleaned up and go into the conv...\n","            w = self.weight * self.w_mul\n","            w = w.permute(1, 0, 2, 3)\n","            # probably applying a conv on w would be more efficient. also this quadruples the weight (average)?!\n","            w = F.pad(w, (1,1,1,1))\n","            w = w[:, :, 1:, 1:]+ w[:, :, :-1, 1:] + w[:, :, 1:, :-1] + w[:, :, :-1, :-1]\n","            x = F.conv_transpose2d(x, w, stride=2, padding=(w.size(-1)-1)//2)\n","            have_convolution = True\n","        elif self.upscale is not None:\n","            x = self.upscale(x)\n","\n","        if not have_convolution and self.intermediate is None:\n","            return F.conv2d(x, self.weight * self.w_mul, bias, padding=self.kernel_size//2)\n","        elif not have_convolution:\n","            x = F.conv2d(x, self.weight * self.w_mul, None, padding=self.kernel_size//2)\n","\n","        if self.intermediate is not None:\n","            x = self.intermediate(x)\n","        if bias is not None:\n","            x = x + bias.view(1, -1, 1, 1)\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.745327Z","iopub.execute_input":"2021-06-24T11:13:07.745692Z","iopub.status.idle":"2021-06-24T11:13:07.761544Z","shell.execute_reply.started":"2021-06-24T11:13:07.745656Z","shell.execute_reply":"2021-06-24T11:13:07.760334Z"},"trusted":true,"id":"pkXScRgBPJIa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> Using the same metric(targeted initialization)"],"metadata":{"id":"bj29gxPfPJIb"}},{"cell_type":"markdown","source":["Let's look at the schematic again at this point."],"metadata":{"id":"9dnqJUI0PJIb"}},{"cell_type":"markdown","source":["![image](https://www.researchgate.net/publication/343021405/figure/fig3/AS:915394470625280@1595258457162/Generator-architecture-of-the-StyleGAN-neural-network-1.png)"],"metadata":{"id":"UDo5NndOPJIb"}},{"cell_type":"markdown","source":["> For each block, 2 noises and 2 styles are continuously injected."],"metadata":{"id":"UL3BPsZ7PJIb"}},{"cell_type":"markdown","source":["**2-c. Noise Layer**"],"metadata":{"id":"MpkWcrHsPJIc"}},{"cell_type":"code","source":["class NoiseLayer(nn.Module):\n","    \"\"\"adds noise. noise is per pixel (constant over channels) with per-channel weight\"\"\"\n","    def __init__(self, channels):\n","        super().__init__()\n","        self.weight = nn.Parameter(torch.zeros(channels))\n","        self.noise = None\n","\n","    def forward(self, x, noise=None):\n","        if noise is None and self.noise is None:\n","            noise = torch.randn(x.size(0), 1, x.size(2), x.size(3), device=x.device, dtype=x.dtype)\n","        elif noise is None:\n","            # here is a little trick: if you get all the noiselayers and set each\n","            # modules .noise attribute, you can have pre-defined noise.\n","            # Very useful for analysis\n","            noise = self.noise\n","        x = x + self.weight.view(1, -1, 1, 1) * noise\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.763072Z","iopub.execute_input":"2021-06-24T11:13:07.763496Z","iopub.status.idle":"2021-06-24T11:13:07.773833Z","shell.execute_reply.started":"2021-06-24T11:13:07.763457Z","shell.execute_reply":"2021-06-24T11:13:07.773014Z"},"trusted":true,"id":"8ILHriHFPJIc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["![image](https://bloglunit.files.wordpress.com/2019/02/1_gwchaliormc1xlj7bh0zmg.png)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:10:36.184569Z","iopub.execute_input":"2021-06-24T03:10:36.184996Z","iopub.status.idle":"2021-06-24T03:10:36.909949Z","shell.execute_reply.started":"2021-06-24T03:10:36.184943Z","shell.execute_reply":"2021-06-24T03:10:36.908884Z"},"id":"9TDZfJngPJIc"}},{"cell_type":"markdown","source":["- The noise layer receives the channels and returns the channels to which the noise is applied.\n","- The noise layer adds gaussian noise of learnable standard deviation"],"metadata":{"id":"6IQvMxwBPJIc"}},{"cell_type":"markdown","source":["**2-d. Style Modification Layer**"],"metadata":{"id":"0v22eNqBPJId"}},{"cell_type":"code","source":["class StyleMod(nn.Module):\n","    def __init__(self, latent_size, channels, use_wscale):\n","        super(StyleMod, self).__init__()\n","        self.lin = MyLinear(latent_size,\n","                            channels * 2,\n","                            gain=1.0, use_wscale=use_wscale)\n","\n","    def forward(self, x, latent):\n","        style = self.lin(latent) # style => [batch_size, n_channels*2]\n","        shape = [-1, 2, x.size(1)] + (x.dim() - 2) * [1]\n","        style = style.view(shape)  # [batch_size, 2, n_channels, ...]\n","        x = x * (style[:, 0] + 1.) + style[:, 1]\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.775169Z","iopub.execute_input":"2021-06-24T11:13:07.775601Z","iopub.status.idle":"2021-06-24T11:13:07.786108Z","shell.execute_reply.started":"2021-06-24T11:13:07.775507Z","shell.execute_reply":"2021-06-24T11:13:07.785343Z"},"trusted":true,"id":"3Hx_Ad5vPJId"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["![image](https://bloglunit.files.wordpress.com/2019/02/0_uqn4slmhrfykfmjs.png)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T03:09:17.125418Z","iopub.execute_input":"2021-06-24T03:09:17.125816Z","iopub.status.idle":"2021-06-24T03:09:17.872007Z","shell.execute_reply.started":"2021-06-24T03:09:17.125783Z","shell.execute_reply":"2021-06-24T03:09:17.870376Z"},"id":"FhYHlPL6PJIo"}},{"cell_type":"markdown","source":["> TEST CODE :"],"metadata":{"id":"2dFZEldhPJIp"}},{"cell_type":"code","source":["lin = MyLinear(512, 3*2, 1.0, use_wscale=True)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.787417Z","iopub.execute_input":"2021-06-24T11:13:07.787986Z","iopub.status.idle":"2021-06-24T11:13:07.796506Z","shell.execute_reply.started":"2021-06-24T11:13:07.787949Z","shell.execute_reply":"2021-06-24T11:13:07.795684Z"},"trusted":true,"id":"LTNqvWlyPJIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent1 = torch.from_numpy(np.random.randn(3,512).astype(np.float64))\n","latent2 = torch.from_numpy(np.random.randn(3,512).astype(np.float64))\n","latent = torch.cat([latent1,latent2], axis=0)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.79962Z","iopub.execute_input":"2021-06-24T11:13:07.799958Z","iopub.status.idle":"2021-06-24T11:13:07.807528Z","shell.execute_reply.started":"2021-06-24T11:13:07.799924Z","shell.execute_reply":"2021-06-24T11:13:07.806614Z"},"trusted":true,"id":"ZxYj1U53PJIp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latent.size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.810707Z","iopub.execute_input":"2021-06-24T11:13:07.811011Z","iopub.status.idle":"2021-06-24T11:13:07.819432Z","shell.execute_reply.started":"2021-06-24T11:13:07.810984Z","shell.execute_reply":"2021-06-24T11:13:07.818541Z"},"trusted":true,"id":"oQSAqUI2PJIp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-e. Pixel Normalization Layer**"],"metadata":{"id":"PcUJDU4cPJIq"}},{"cell_type":"code","source":["class PixelNormLayer(nn.Module):\n","    def __init__(self, epsilon=1e-8):\n","        super().__init__()\n","        self.epsilon = epsilon\n","    def forward(self, x):\n","        return x * torch.rsqrt(torch.mean(x**2, dim=1, keepdim=True) + self.epsilon)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.822034Z","iopub.execute_input":"2021-06-24T11:13:07.822616Z","iopub.status.idle":"2021-06-24T11:13:07.828439Z","shell.execute_reply.started":"2021-06-24T11:13:07.822578Z","shell.execute_reply":"2021-06-24T11:13:07.827634Z"},"trusted":true,"id":"znJpO9KYPJIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-f. Blur Layer**"],"metadata":{"id":"dqomte5cPJIq"}},{"cell_type":"code","source":["class BlurLayer(nn.Module):\n","    def __init__(self, kernel=[1, 2, 1], normalize=True, flip=False, stride=1):\n","        super(BlurLayer, self).__init__()\n","        kernel=[1, 2, 1]\n","        kernel = torch.tensor(kernel, dtype=torch.float32)\n","        kernel = kernel[:, None] * kernel[None, :]\n","        kernel = kernel[None, None]\n","        if normalize:\n","            kernel = kernel / kernel.sum()\n","        if flip:\n","            kernel = kernel[:, :, ::-1, ::-1]\n","        self.register_buffer('kernel', kernel)\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        # expand kernel channels\n","        kernel = self.kernel.expand(x.size(1), -1, -1, -1)\n","        x = F.conv2d(\n","            x,\n","            kernel,\n","            stride=self.stride,\n","            padding=int((self.kernel.size(2)-1)/2),\n","            groups=x.size(1)\n","        )\n","        return x\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.82959Z","iopub.execute_input":"2021-06-24T11:13:07.830122Z","iopub.status.idle":"2021-06-24T11:13:07.840541Z","shell.execute_reply.started":"2021-06-24T11:13:07.83007Z","shell.execute_reply":"2021-06-24T11:13:07.839653Z"},"trusted":true,"id":"7YzRM6BRPJIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**2-g. Upscaling Layer**"],"metadata":{"id":"Z2_moORRPJIr"}},{"cell_type":"code","source":["def upscale2d(x, factor=2, gain=1):\n","    assert x.dim() == 4\n","    if gain != 1:\n","        x = x * gain\n","    if factor != 1:\n","        shape = x.shape\n","        x = x.view(shape[0], shape[1], shape[2], 1, shape[3], 1).expand(-1, -1, -1, factor, -1, factor)\n","        x = x.contiguous().view(shape[0], shape[1], factor * shape[2], factor * shape[3])\n","    return x\n","\n","class Upscale2d(nn.Module):\n","    def __init__(self, factor=2, gain=1):\n","        super().__init__()\n","        assert isinstance(factor, int) and factor >= 1\n","        self.gain = gain\n","        self.factor = factor\n","    def forward(self, x):\n","        return upscale2d(x, factor=self.factor, gain=self.gain)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.841662Z","iopub.execute_input":"2021-06-24T11:13:07.842049Z","iopub.status.idle":"2021-06-24T11:13:07.852342Z","shell.execute_reply.started":"2021-06-24T11:13:07.84201Z","shell.execute_reply":"2021-06-24T11:13:07.851298Z"},"trusted":true,"id":"gaWPUWD2PJIr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 3. Design Networks"],"metadata":{"id":"29hK4PQjPJIr"}},{"cell_type":"markdown","source":["**3-a. Generator Mapping Network**"],"metadata":{"id":"1RcZC8UpPJIs"}},{"cell_type":"code","source":["class G_mapping(nn.Sequential):\n","    def __init__(self, nonlinearity='lrelu', use_wscale=True):\n","        act, gain = {'relu': (torch.relu, np.sqrt(2)),\n","                     'lrelu': (nn.LeakyReLU(negative_slope=0.2), np.sqrt(2))}[nonlinearity]\n","        layers = [\n","            ('pixel_norm', PixelNormLayer()),\n","            ('dense0', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense0_act', act),\n","            ('dense1', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense1_act', act),\n","            ('dense2', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense2_act', act),\n","            ('dense3', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense3_act', act),\n","            ('dense4', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense4_act', act),\n","            ('dense5', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense5_act', act),\n","            ('dense6', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense6_act', act),\n","            ('dense7', MyLinear(512, 512, gain=gain, lrmul=0.01, use_wscale=use_wscale)),\n","            ('dense7_act', act)\n","        ]\n","        super().__init__(OrderedDict(layers))\n","\n","    def forward(self, x):\n","        x = super().forward(x)\n","        # Broadcast\n","        x = x.unsqueeze(1).expand(-1, 18, -1)\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.854003Z","iopub.execute_input":"2021-06-24T11:13:07.854454Z","iopub.status.idle":"2021-06-24T11:13:07.868106Z","shell.execute_reply.started":"2021-06-24T11:13:07.854418Z","shell.execute_reply":"2021-06-24T11:13:07.86715Z"},"trusted":true,"id":"N8u_ALVOPJIs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> sampling latent `z`(gaussian distribution) --> return `w` vector\n","\n","> style information is contained in `w`\n"],"metadata":{"id":"EmiLJxqWPJIs"}},{"cell_type":"code","source":["class Truncation(nn.Module):\n","    def __init__(self, avg_latent, max_layer=8, threshold=0.7):\n","        super().__init__()\n","        self.max_layer = max_layer\n","        self.threshold = threshold\n","        self.register_buffer('avg_latent', avg_latent)\n","    def forward(self, x):\n","        assert x.dim() == 3\n","        interp = torch.lerp(self.avg_latent, x, self.threshold)\n","        do_trunc = (torch.arange(x.size(1)) < self.max_layer).view(1, -1, 1)\n","        return torch.where(do_trunc, interp, x)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.869599Z","iopub.execute_input":"2021-06-24T11:13:07.870284Z","iopub.status.idle":"2021-06-24T11:13:07.878181Z","shell.execute_reply.started":"2021-06-24T11:13:07.870245Z","shell.execute_reply":"2021-06-24T11:13:07.877255Z"},"trusted":true,"id":"Fn1TjmUlPJIt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3-b. Generator Synthesis Blocks**"],"metadata":{"id":"971PCPgWPJIt"}},{"cell_type":"code","source":["class LayerEpilogue(nn.Module):\n","    \"\"\"Things to do at the end of each layer.\"\"\"\n","    def __init__(self, channels, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer):\n","        super().__init__()\n","        layers = []\n","        if use_noise:\n","            layers.append(('noise', NoiseLayer(channels)))\n","        layers.append(('activation', activation_layer))\n","        if use_pixel_norm:\n","            layers.append(('pixel_norm', PixelNorm()))\n","        if use_instance_norm:\n","            layers.append(('instance_norm', nn.InstanceNorm2d(channels)))\n","        self.top_epi = nn.Sequential(OrderedDict(layers))\n","        if use_styles:\n","            self.style_mod = StyleMod(dlatent_size, channels, use_wscale=use_wscale)\n","        else:\n","            self.style_mod = None\n","    def forward(self, x, dlatents_in_slice=None):\n","        x = self.top_epi(x)\n","        if self.style_mod is not None:\n","            x = self.style_mod(x, dlatents_in_slice)\n","        else:\n","            assert dlatents_in_slice is None\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.879406Z","iopub.execute_input":"2021-06-24T11:13:07.87997Z","iopub.status.idle":"2021-06-24T11:13:07.889244Z","shell.execute_reply.started":"2021-06-24T11:13:07.879932Z","shell.execute_reply":"2021-06-24T11:13:07.888124Z"},"trusted":true,"id":"vVwg3e7cPJIt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class InputBlock(nn.Module):\n","    def __init__(self, nf, dlatent_size, const_input_layer, gain, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer):\n","        super().__init__()\n","        self.const_input_layer = const_input_layer\n","        self.nf = nf\n","        if self.const_input_layer:\n","            # called 'const' in tf\n","            self.const = nn.Parameter(torch.ones(1, nf, 4, 4))\n","            self.bias = nn.Parameter(torch.ones(nf))\n","        else:\n","            self.dense = MyLinear(dlatent_size, nf*16, gain=gain/4, use_wscale=use_wscale) # tweak gain to match the official implementation of Progressing GAN\n","        self.epi1 = LayerEpilogue(nf, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer)\n","        self.conv = MyConv2d(nf, nf, 3, gain=gain, use_wscale=use_wscale)\n","        self.epi2 = LayerEpilogue(nf, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer)\n","\n","    def forward(self, dlatents_in_range):\n","        batch_size = dlatents_in_range.size(0)\n","        if self.const_input_layer:\n","            x = self.const.expand(batch_size, -1, -1, -1)\n","            x = x + self.bias.view(1, -1, 1, 1)\n","        else:\n","            x = self.dense(dlatents_in_range[:, 0]).view(batch_size, self.nf, 4, 4)\n","        x = self.epi1(x, dlatents_in_range[:, 0])\n","        x = self.conv(x)\n","        x = self.epi2(x, dlatents_in_range[:, 1])\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.890687Z","iopub.execute_input":"2021-06-24T11:13:07.891261Z","iopub.status.idle":"2021-06-24T11:13:07.903769Z","shell.execute_reply.started":"2021-06-24T11:13:07.891224Z","shell.execute_reply":"2021-06-24T11:13:07.902864Z"},"trusted":true,"id":"svBDKSlvPJIu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class GSynthesisBlock(nn.Module):\n","    def __init__(self, in_channels, out_channels, blur_filter, dlatent_size, gain, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer):\n","        # 2**res x 2**res # res = 3..resolution_log2\n","        super().__init__()\n","        if blur_filter:\n","            blur = BlurLayer(blur_filter)\n","        else:\n","            blur = None\n","        self.conv0_up = MyConv2d(in_channels, out_channels, kernel_size=3, gain=gain, use_wscale=use_wscale,\n","                                 intermediate=blur, upscale=True)\n","        self.epi1 = LayerEpilogue(out_channels, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer)\n","        self.conv1 = MyConv2d(out_channels, out_channels, kernel_size=3, gain=gain, use_wscale=use_wscale)\n","        self.epi2 = LayerEpilogue(out_channels, dlatent_size, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, activation_layer)\n","\n","    def forward(self, x, dlatents_in_range):\n","        x = self.conv0_up(x)\n","        x = self.epi1(x, dlatents_in_range[:, 0])\n","        x = self.conv1(x)\n","        x = self.epi2(x, dlatents_in_range[:, 1])\n","        return x"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.908347Z","iopub.execute_input":"2021-06-24T11:13:07.908632Z","iopub.status.idle":"2021-06-24T11:13:07.917353Z","shell.execute_reply.started":"2021-06-24T11:13:07.908607Z","shell.execute_reply":"2021-06-24T11:13:07.916447Z"},"trusted":true,"id":"AG1eNoYgPJIu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3-c. Generator Synthesis Network**"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T09:02:59.485386Z","iopub.execute_input":"2021-06-24T09:02:59.485711Z","iopub.status.idle":"2021-06-24T09:02:59.491471Z","shell.execute_reply.started":"2021-06-24T09:02:59.485682Z","shell.execute_reply":"2021-06-24T09:02:59.490131Z"},"id":"K1oF_IP8PJIv"}},{"cell_type":"code","source":["class G_synthesis(nn.Module):\n","    def __init__(self,\n","        dlatent_size        = 512,          # Disentangled latent (W) dimensionality.\n","        num_channels        = 3,            # Number of output color channels.\n","        resolution          = 1024,         # Output resolution.\n","        fmap_base           = 8192,         # Overall multiplier for the number of feature maps.\n","        fmap_decay          = 1.0,          # log2 feature map reduction when doubling the resolution.\n","        fmap_max            = 512,          # Maximum number of feature maps in any layer.\n","        use_styles          = True,         # Enable style inputs?\n","        const_input_layer   = True,         # First layer is a learned constant?\n","        use_noise           = True,         # Enable noise inputs?\n","        randomize_noise     = True,         # True = randomize noise inputs every time (non-deterministic), False = read noise inputs from variables.\n","        nonlinearity        = 'lrelu',      # Activation function: 'relu', 'lrelu'\n","        use_wscale          = True,         # Enable equalized learning rate?\n","        use_pixel_norm      = False,        # Enable pixelwise feature vector normalization?\n","        use_instance_norm   = True,         # Enable instance normalization?\n","        dtype               = torch.float32,  # Data type to use for activations and outputs.\n","        blur_filter         = [1,2,1],      # Low-pass filter to apply when resampling activations. None = no filtering.\n","        ):\n","\n","        super().__init__()\n","        def nf(stage):\n","            return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n","        self.dlatent_size = dlatent_size\n","        resolution_log2 = int(np.log2(resolution))\n","        assert resolution == 2**resolution_log2 and resolution >= 4\n","\n","        act, gain = {'relu': (torch.relu, np.sqrt(2)),\n","                     'lrelu': (nn.LeakyReLU(negative_slope=0.2), np.sqrt(2))}[nonlinearity]\n","        num_layers = resolution_log2 * 2 - 2\n","        num_styles = num_layers if use_styles else 1\n","        torgbs = []\n","        blocks = []\n","        for res in range(2, resolution_log2 + 1):\n","            channels = nf(res-1)\n","            name = '{s}x{s}'.format(s=2**res)\n","            if res == 2:\n","                blocks.append((name,\n","                               InputBlock(channels, dlatent_size, const_input_layer, gain, use_wscale,\n","                                      use_noise, use_pixel_norm, use_instance_norm, use_styles, act)))\n","\n","            else:\n","                blocks.append((name,\n","                               GSynthesisBlock(last_channels, channels, blur_filter, dlatent_size, gain, use_wscale, use_noise, use_pixel_norm, use_instance_norm, use_styles, act)))\n","            last_channels = channels\n","        self.torgb = MyConv2d(channels, num_channels, 1, gain=1, use_wscale=use_wscale)\n","        self.blocks = nn.ModuleDict(OrderedDict(blocks))\n","\n","    def forward(self, dlatents_in):\n","        # Input: Disentangled latents (W) [minibatch, num_layers, dlatent_size].\n","        # lod_in = tf.cast(tf.get_variable('lod', initializer=np.float32(0), trainable=False), dtype)\n","        batch_size = dlatents_in.size(0)\n","        for i, m in enumerate(self.blocks.values()):\n","            if i == 0:\n","                x = m(dlatents_in[:, 2*i:2*i+2])\n","            else:\n","                x = m(x, dlatents_in[:, 2*i:2*i+2])\n","        rgb = self.torgb(x)\n","        return rgb"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.919337Z","iopub.execute_input":"2021-06-24T11:13:07.919971Z","iopub.status.idle":"2021-06-24T11:13:07.935883Z","shell.execute_reply.started":"2021-06-24T11:13:07.919918Z","shell.execute_reply":"2021-06-24T11:13:07.935024Z"},"trusted":true,"id":"3ZE-jcPZPJIv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 4. Define the Model (Image Generator)"],"metadata":{"id":"JsW_LuB9PJIv"}},{"cell_type":"markdown","source":["**4-a. data flow : z to image**"],"metadata":{"id":"ayvB4ROZPJIw"}},{"cell_type":"code","source":["g_all = nn.Sequential(OrderedDict([\n","    ('g_mapping', G_mapping()),\n","    ('g_synthesis', G_synthesis())\n","]))\n"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:07.938345Z","iopub.execute_input":"2021-06-24T11:13:07.938716Z","iopub.status.idle":"2021-06-24T11:13:08.274733Z","shell.execute_reply.started":"2021-06-24T11:13:07.938677Z","shell.execute_reply":"2021-06-24T11:13:08.273849Z"},"trusted":true,"id":"ZZ7K0TZhPJIw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["> If latent z is put into g_mapping network, w is returned, and if the returned w is put into g_synthesis, an image is created. This process is chained sequentially and occurs one after another."],"metadata":{"id":"v-SbFmbOPJIx"}},{"cell_type":"markdown","source":["**4-b. load pre-trained weight**"],"metadata":{"id":"zVeAICqoPJIx"}},{"cell_type":"code","source":["import os\n","os.listdir('../input/ffhq-1024x1024-pretrained')"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:08.277032Z","iopub.execute_input":"2021-06-24T11:13:08.277627Z","iopub.status.idle":"2021-06-24T11:13:08.287672Z","shell.execute_reply.started":"2021-06-24T11:13:08.277586Z","shell.execute_reply":"2021-06-24T11:13:08.286674Z"},"trusted":true,"id":"0_QSzz8mPJIx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["g_all.load_state_dict(torch.load('../input/ffhq-1024x1024-pretrained/karras2019stylegan-ffhq-1024x1024.for_g_all.pt'))"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:08.289428Z","iopub.execute_input":"2021-06-24T11:13:08.290004Z","iopub.status.idle":"2021-06-24T11:13:08.386943Z","shell.execute_reply.started":"2021-06-24T11:13:08.289967Z","shell.execute_reply":"2021-06-24T11:13:08.386038Z"},"trusted":true,"id":"TEmyZOS3PJIy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 5. Test the Model"],"metadata":{"id":"7hsLJdiwPJIy"}},{"cell_type":"markdown","source":["**5-a. gpu setting**"],"metadata":{"id":"xak9oOKAPJIy"}},{"cell_type":"code","source":["device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n","g_all.eval()\n","g_all.to(device)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:08.388185Z","iopub.execute_input":"2021-06-24T11:13:08.38853Z","iopub.status.idle":"2021-06-24T11:13:10.257126Z","shell.execute_reply.started":"2021-06-24T11:13:08.388493Z","shell.execute_reply":"2021-06-24T11:13:10.256152Z"},"trusted":true,"id":"XNmdyvryPJIy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5-b. input setting - grid**"],"metadata":{"id":"hVmnwPCfPJIz"}},{"cell_type":"code","source":["nb_rows = 3\n","nb_cols = 3\n","nb_samples = nb_rows * nb_cols"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:10.258515Z","iopub.execute_input":"2021-06-24T11:13:10.258876Z","iopub.status.idle":"2021-06-24T11:13:10.263073Z","shell.execute_reply.started":"2021-06-24T11:13:10.258839Z","shell.execute_reply":"2021-06-24T11:13:10.262181Z"},"trusted":true,"id":"m1SQvsKJPJIz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5-c. input setting - latent z**"],"metadata":{"id":"zpr0tTKaPJIz"}},{"cell_type":"code","source":["latents = torch.randn(nb_samples, 512, device=device)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:10.264408Z","iopub.execute_input":"2021-06-24T11:13:10.26475Z","iopub.status.idle":"2021-06-24T11:13:10.278036Z","shell.execute_reply.started":"2021-06-24T11:13:10.264716Z","shell.execute_reply":"2021-06-24T11:13:10.277241Z"},"trusted":true,"id":"MGgZWbRuPJI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latents"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:10.279297Z","iopub.execute_input":"2021-06-24T11:13:10.279668Z","iopub.status.idle":"2021-06-24T11:13:10.292969Z","shell.execute_reply.started":"2021-06-24T11:13:10.279633Z","shell.execute_reply":"2021-06-24T11:13:10.291973Z"},"trusted":true,"id":"zUoAFstSPJI0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["latents.shape"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:10.294265Z","iopub.execute_input":"2021-06-24T11:13:10.294662Z","iopub.status.idle":"2021-06-24T11:13:10.29993Z","shell.execute_reply.started":"2021-06-24T11:13:10.294623Z","shell.execute_reply":"2021-06-24T11:13:10.299027Z"},"trusted":true,"id":"Bgwr00cjPJI1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**5-d. show samples**"],"metadata":{"id":"TdK63fFCPJI1"}},{"cell_type":"code","source":["import torchvision\n","import matplotlib.pyplot as plt"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:10.301232Z","iopub.execute_input":"2021-06-24T11:13:10.30172Z","iopub.status.idle":"2021-06-24T11:13:10.348898Z","shell.execute_reply.started":"2021-06-24T11:13:10.301684Z","shell.execute_reply":"2021-06-24T11:13:10.348154Z"},"trusted":true,"id":"9dMaZCZAPJI1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with torch.no_grad():\n","    imgs = g_all(latents)\n","    imgs = (imgs.clamp(-1, 1)+1)/2.0  # normalization to 0~1 range\n","imgs = imgs.cpu()\n","\n","imgs = torchvision.utils.make_grid(imgs, nrow=nb_cols)\n","\n","plt.figure(figsize=(15,6))\n","plt.imshow(imgs.permute(1,2,0).detach().numpy())\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:10.350081Z","iopub.execute_input":"2021-06-24T11:13:10.350473Z","iopub.status.idle":"2021-06-24T11:13:13.223111Z","shell.execute_reply.started":"2021-06-24T11:13:10.350436Z","shell.execute_reply":"2021-06-24T11:13:13.222213Z"},"trusted":true,"id":"vtUsUP4wPJI1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step 6. Control Latent Vector"],"metadata":{"id":"DiPs7zg9PJI2"}},{"cell_type":"markdown","source":["**6-a. first random latent vector + generate first image**"],"metadata":{"id":"2ZlkvBubPJI2"}},{"cell_type":"code","source":["latent1 = torch.randn(1, 512, device=device)\n","img1 = g_all(latent1)\n","img1 = img1.clamp(-1,1)+1/2.0\n","img1 = img1.cpu()\n","\n","img1.shape"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:29.904551Z","iopub.execute_input":"2021-06-24T11:13:29.905184Z","iopub.status.idle":"2021-06-24T11:13:30.003664Z","shell.execute_reply.started":"2021-06-24T11:13:29.90514Z","shell.execute_reply":"2021-06-24T11:13:30.002877Z"},"trusted":true,"id":"dK_dzwL3PJI2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img1.squeeze().permute(1,2,0).detach().numpy()) # drop batch (4dim -> 3dim)\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:31.145043Z","iopub.execute_input":"2021-06-24T11:13:31.145411Z","iopub.status.idle":"2021-06-24T11:13:31.381647Z","shell.execute_reply.started":"2021-06-24T11:13:31.145379Z","shell.execute_reply":"2021-06-24T11:13:31.380566Z"},"trusted":true,"id":"8n-ygPZnPJI2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6-b. second random latent vector + generate second image**"],"metadata":{"id":"6bYjgfTdPJI3"}},{"cell_type":"code","source":["latent2 = torch.randn(1, 512, device=device)\n","img2 = g_all(latent2)\n","img2 = img2.clamp(-1,1)+1/2.0\n","img2 = img2.cpu()\n","\n","img2.shape"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:50.255644Z","iopub.execute_input":"2021-06-24T11:13:50.25598Z","iopub.status.idle":"2021-06-24T11:13:50.349341Z","shell.execute_reply.started":"2021-06-24T11:13:50.255947Z","shell.execute_reply":"2021-06-24T11:13:50.348367Z"},"trusted":true,"id":"6Oq3KhCIPJI3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img2.squeeze().permute(1,2,0).detach().numpy()) # drop batch (4dim -> 3dim)\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:13:50.405365Z","iopub.execute_input":"2021-06-24T11:13:50.405623Z","iopub.status.idle":"2021-06-24T11:13:50.62966Z","shell.execute_reply.started":"2021-06-24T11:13:50.405597Z","shell.execute_reply":"2021-06-24T11:13:50.628819Z"},"trusted":true,"id":"QJpGbmhsPJI3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6-c. half `z` + half `z`**"],"metadata":{"id":"COOypCnqPJI3"}},{"cell_type":"code","source":["new_img = g_all(latent1*0.5 + latent2*0.5)\n","new_img = new_img.clamp(-1,1)+1/2.0\n","new_img = new_img.cpu()\n","\n","new_img.shape"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:16:48.037049Z","iopub.execute_input":"2021-06-24T11:16:48.037423Z","iopub.status.idle":"2021-06-24T11:16:48.140562Z","shell.execute_reply.started":"2021-06-24T11:16:48.037391Z","shell.execute_reply":"2021-06-24T11:16:48.139576Z"},"trusted":true,"id":"vtk9NXurPJI4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(new_img.squeeze().permute(1,2,0).detach().numpy())\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:16:48.196168Z","iopub.execute_input":"2021-06-24T11:16:48.196431Z","iopub.status.idle":"2021-06-24T11:16:48.425957Z","shell.execute_reply.started":"2021-06-24T11:16:48.196405Z","shell.execute_reply":"2021-06-24T11:16:48.424936Z"},"trusted":true,"id":"ZwY7SIOWPJI4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**6-d. half `w` + half `w`**"],"metadata":{"id":"dLadu3t4PJI4"}},{"cell_type":"markdown","source":["By the way, we actually have a w vector that passed through the G_mapping network. Let's try it."],"metadata":{"id":"RWT3TGR8PJI4"}},{"cell_type":"code","source":["g_mapping = g_all[0] # We can extract mapping network like this.\n","g_mapping"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:22:23.434853Z","iopub.execute_input":"2021-06-24T11:22:23.435217Z","iopub.status.idle":"2021-06-24T11:22:23.441944Z","shell.execute_reply.started":"2021-06-24T11:22:23.435185Z","shell.execute_reply":"2021-06-24T11:22:23.440972Z"},"trusted":true,"id":"l84Ee_ymPJI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["g_synthesis = g_all[1]# Similarly, synthesis network can be extracted like this."],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:22:15.877934Z","iopub.execute_input":"2021-06-24T11:22:15.878299Z","iopub.status.idle":"2021-06-24T11:22:15.884573Z","shell.execute_reply.started":"2021-06-24T11:22:15.878265Z","shell.execute_reply":"2021-06-24T11:22:15.883689Z"},"trusted":true,"id":"xhmpj0vIPJI5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["w_1 = g_mapping(latent1)\n","w_2 = g_mapping(latent2)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:24:47.782707Z","iopub.execute_input":"2021-06-24T11:24:47.783052Z","iopub.status.idle":"2021-06-24T11:24:47.793186Z","shell.execute_reply.started":"2021-06-24T11:24:47.78302Z","shell.execute_reply":"2021-06-24T11:24:47.792374Z"},"trusted":true,"id":"HpKpSYUGPJI5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The results through the MLP mapping network are as follows."],"metadata":{"id":"3xB6InrSPJI5"}},{"cell_type":"code","source":["print(latent1.size(), w_1.size())\n","print(latent2.size(), w_2.size())"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:25:14.275013Z","iopub.execute_input":"2021-06-24T11:25:14.275413Z","iopub.status.idle":"2021-06-24T11:25:14.281137Z","shell.execute_reply.started":"2021-06-24T11:25:14.275374Z","shell.execute_reply":"2021-06-24T11:25:14.280017Z"},"trusted":true,"id":"yljnSbu4PJI5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["then, let's convert to image (half + half)"],"metadata":{"id":"_PbigK5sPJI6"}},{"cell_type":"code","source":["img3 = g_synthesis(w_1*0.5 + w_2*0.5)\n","img3 = img3.clamp(-1,1)+1/2.0\n","img3 = img3.cpu()\n","\n","img3.shape"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:27:58.384711Z","iopub.execute_input":"2021-06-24T11:27:58.385041Z","iopub.status.idle":"2021-06-24T11:27:58.485821Z","shell.execute_reply.started":"2021-06-24T11:27:58.385009Z","shell.execute_reply":"2021-06-24T11:27:58.484853Z"},"trusted":true,"id":"sVla1ZLvPJI6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(img3.squeeze().permute(1,2,0).detach().numpy())\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:27:59.375232Z","iopub.execute_input":"2021-06-24T11:27:59.375582Z","iopub.status.idle":"2021-06-24T11:27:59.620006Z","shell.execute_reply.started":"2021-06-24T11:27:59.375551Z","shell.execute_reply":"2021-06-24T11:27:59.619167Z"},"trusted":true,"id":"NLzQcuGMPJI6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Yes! I think this looks more like a `half+half`\n","\n","And It is a really surprising result that it is estimated to be in the middle even by age."],"metadata":{"id":"sum6dV08PJI6"}},{"cell_type":"markdown","source":["**6-e. Image Interpolation Comparison**"],"metadata":{"id":"sXgZqaAJPJI7"}},{"cell_type":"code","source":["itp_imgs = []\n","\n","with torch.no_grad():\n","    for a in np.linspace(0, 1, 10):\n","        z = ((1-a) * latent1) + (a * latent2)\n","        result = g_all(z)\n","        result = result.clamp(-1,1)+1/2.0\n","        result = result.cpu()\n","        itp_imgs.append(result)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:36:28.951412Z","iopub.execute_input":"2021-06-24T11:36:28.951854Z","iopub.status.idle":"2021-06-24T11:36:29.877875Z","shell.execute_reply.started":"2021-06-24T11:36:28.95182Z","shell.execute_reply":"2021-06-24T11:36:29.876956Z"},"trusted":true,"id":"HEdFNFKVPJI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itp_imgs[0].size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:36:50.807341Z","iopub.execute_input":"2021-06-24T11:36:50.807661Z","iopub.status.idle":"2021-06-24T11:36:50.813293Z","shell.execute_reply.started":"2021-06-24T11:36:50.807632Z","shell.execute_reply":"2021-06-24T11:36:50.812211Z"},"trusted":true,"id":"Of0NmgHxPJI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itp_imgs = torch.cat(itp_imgs)\n","itp_imgs.size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:37:47.536764Z","iopub.execute_input":"2021-06-24T11:37:47.537079Z","iopub.status.idle":"2021-06-24T11:37:47.611194Z","shell.execute_reply.started":"2021-06-24T11:37:47.537049Z","shell.execute_reply":"2021-06-24T11:37:47.610201Z"},"trusted":true,"id":"26i30_auPJI7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid_img = torchvision.utils.make_grid(itp_imgs, nrow=5)\n","grid_img.size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:38:36.809893Z","iopub.execute_input":"2021-06-24T11:38:36.810248Z","iopub.status.idle":"2021-06-24T11:38:36.906493Z","shell.execute_reply.started":"2021-06-24T11:38:36.810215Z","shell.execute_reply":"2021-06-24T11:38:36.905494Z"},"trusted":true,"id":"P8O3eIUUPJI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(grid_img.permute(1,2,0).detach().numpy())\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:39:25.855037Z","iopub.execute_input":"2021-06-24T11:39:25.855478Z","iopub.status.idle":"2021-06-24T11:39:27.618023Z","shell.execute_reply.started":"2021-06-24T11:39:25.855433Z","shell.execute_reply":"2021-06-24T11:39:27.616999Z"},"trusted":true,"id":"UOyH_QLUPJI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itp_imgs2 = []\n","\n","with torch.no_grad():\n","    for a in np.linspace(0, 1, 10):\n","        w = ((1-a) * w_1) + (a * w_2)\n","        result2 = g_synthesis(w)\n","        result2 = result2.clamp(-1,1)+1/2.0\n","        result2 = result2.cpu()\n","        itp_imgs2.append(result2)"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:40:09.765658Z","iopub.execute_input":"2021-06-24T11:40:09.766141Z","iopub.status.idle":"2021-06-24T11:40:10.685298Z","shell.execute_reply.started":"2021-06-24T11:40:09.766081Z","shell.execute_reply":"2021-06-24T11:40:10.684454Z"},"trusted":true,"id":"qYv6cthUPJI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itp_imgs2[0].size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:40:31.160123Z","iopub.execute_input":"2021-06-24T11:40:31.16047Z","iopub.status.idle":"2021-06-24T11:40:31.166292Z","shell.execute_reply.started":"2021-06-24T11:40:31.160432Z","shell.execute_reply":"2021-06-24T11:40:31.165207Z"},"trusted":true,"id":"nrDx8FoGPJI8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["itp_imgs2 = torch.cat(itp_imgs2)\n","itp_imgs2.size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:40:34.571432Z","iopub.execute_input":"2021-06-24T11:40:34.571762Z","iopub.status.idle":"2021-06-24T11:40:34.645467Z","shell.execute_reply.started":"2021-06-24T11:40:34.57173Z","shell.execute_reply":"2021-06-24T11:40:34.644458Z"},"trusted":true,"id":"OJnIFxtTPJI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["grid_img2 = torchvision.utils.make_grid(itp_imgs2, nrow=5)\n","grid_img2.size()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:40:45.220741Z","iopub.execute_input":"2021-06-24T11:40:45.221071Z","iopub.status.idle":"2021-06-24T11:40:45.314122Z","shell.execute_reply.started":"2021-06-24T11:40:45.221039Z","shell.execute_reply":"2021-06-24T11:40:45.313141Z"},"trusted":true,"id":"P34sNRhtPJI9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(grid_img2.permute(1,2,0).detach().numpy())\n","plt.axis('off')\n","plt.show()"],"metadata":{"execution":{"iopub.status.busy":"2021-06-24T11:40:51.202207Z","iopub.execute_input":"2021-06-24T11:40:51.202535Z","iopub.status.idle":"2021-06-24T11:40:52.897341Z","shell.execute_reply.started":"2021-06-24T11:40:51.202506Z","shell.execute_reply":"2021-06-24T11:40:52.89636Z"},"trusted":true,"id":"YQC1ifi2PJI9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Yes. It's so much more natural! Here we can see the strengths of stylegan. The traditional image generation model immediately generates an image from a random vector(gaussian distribution) z. That have showed how high the degree of freedom is, in other words, the low degree of feature separation(**It is said to be entangled**). stylegan captured this core 'style' through the mapping network, and we confirmed this through the interpolation results.\n","\n","in Abstract..\n","> The new generator improves the state-of-the-art in terms of traditional distribution quality metrics, leads to demonstrably better interpolation properties, and also better disentangles the latent factors of variation. To quantify interpolation quality and disentanglement, we propose two new, automated methods that are applicable to any generator architecture."],"metadata":{"id":"MFxE7v90PJI9"}}]}